# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from google.colab import files
# Check if the user wants to upload a file or generate one
print("Do you have a CSV file to upload? (yes/no)")
response = input().lower()

if response == "yes":
    # Upload the CSV file
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
else:
    # Generate synthetic classification data
    from sklearn.datasets import make_classification

    X, y = make_classification(n_samples=300, n_features=10, n_classes=2, random_state=42)

    # Combine features and target into a DataFrame
    data = pd.DataFrame(X, columns=[f"Feature_{i}" for i in range(X.shape[1])])
    data['Target'] = y

    # Save the synthetic dataset to a CSV file
    filename = "synthetic_data.csv"
data.to_csv(filename, index=False)
print(f"Synthetic dataset saved as {filename}.")
# Load the dataset
data = pd.read_csv(filename)

# Display the first few rows of the dataset
print("Dataset Preview:")
print(data.head())
# Separate features (X) and target (y)
X = data.iloc[:, :-1].values  # All columns except the last one
y = data.iloc[:, -1].values   # Last column as the target

# Split the dataset into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Initialize and train the Decision Tree model
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, y_train)

# Predict and evaluate
y_pred_tree = decision_tree.predict(X_test)
accuracy_tree = accuracy_score(y_test, y_pred_tree)
print(f"Decision Tree Accuracy: {accuracy_tree:.2f}")
# Initialize the Random Forest model with hyperparameter tuning
random_forest = RandomForestClassifier(n_estimators=100, max_features='sqrt', random_state=42)

# Train the model
random_forest.fit(X_train, y_train)

# Predict and evaluate
y_pred_rf = random_forest.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Accuracy (100 trees, sqrt features): {accuracy_rf:.2f}")
# Experiment with fewer trees and different feature sampling
rf_experiment = RandomForestClassifier(n_estimators=50, max_features=3, random_state=42)
rf_experiment.fit(X_train, y_train)

# Predict and evaluate
y_pred_rf_exp = rf_experiment.predict(X_test)
accuracy_rf_exp = accuracy_score(y_test, y_pred_rf_exp)
print(f"Random Forest Accuracy (50 trees, max_features=3): {accuracy_rf_exp:.2f}")
print("\nModel Comparison:")
print(f"Decision Tree Accuracy: {accuracy_tree:.2f}")
print(f"Random Forest Accuracy (100 trees): {accuracy_rf:.2f}")
print(f"Random Forest Accuracy (50 trees, max_features=3): {accuracy_rf_exp:.2f}")
import matplotlib.pyplot as plt

# Extract feature importance from the Random Forest model
feature_importances = random_forest.feature_importances_

# Plot the feature importance
plt.figure(figsize=(10, 6))
plt.bar(range(len(feature_importances)), feature_importances, tick_label=data.columns[:-1])
plt.title("Feature Importance in Random Forest")
plt.xlabel("Features")
plt.ylabel("Importance")
plt.show()